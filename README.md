# F1_expert: QA-модель по Формуле-1

Этот проект реализует систему вопрос-ответ, которая:
- Парсит статьи о Формуле-1 с русской Википедии
- Генерирует датасет вопрос-ответ
- Обучает модель `rubert-tiny2` на этом датасете
- Предоставляет интерфейс для пользовательского взаимодействия
- Дообучает модель на основе пользовательской оценки


## Функционал кода
- Скачивает статьи из Википедии по категориям, связанным с Формулой-1
- Сохраняет их в структурированном виде
- Формирует корпус текстов и генерирует пары (вопрос, ответ), чистит данные, нормализует текст, удаляет дубликаты
- Обучает модель `rubert-tiny2` на датасете вопрос-ответ
- Использует метрику SQuAD для оценки качества
- Интерфейс в консоли: пользователь задаёт вопрос → получает ответ → ставит оценку (1–5)  
- Модель дообучается на низкооцененных примерах
- Эмбеддинги и FAISS


## Структура проекта

```
F1_expert/
├── F1_expert.py
├── requirements.txt
├── README.md
├── data/
│   └── raw/
├── processed/
│   └── f1_qa_dataset.jsonl
├── models/
│   └── rubert_tiny2_qa/
└── logs/
```
## Использованные модели

| Назначение               | Модель                                                        | Особенности                                 |
|--------------------------|----------------------------------------------------------------|----------------------------------------------|
| Генерация QA             | `cointegrated/rut5-base-multitask`                            | Модель T5, fine-tuned для QA генерации       |
| Извлечение ответа        | `cointegrated/rubert-tiny2`                                   | Легковесный русский BERT                     |
| Семантический поиск      | `sentence-transformers/distiluse-base-multilingual-cased-v2` | Многоязычная модель Sentence Transformers     |
